{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b795278a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.layers as L\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940f8bc0",
   "metadata": {},
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48279434",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b83bbe4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_img(r\"C:\\Users\\ASUS\\Desktop\\coding\\Python\\Deep Learning\\Malaria Cell Detection\\Malarial Cell Image Data\\cell_images\\Parasitized\\C33P1thinF_IMG_20150619_121102a_cell_193.png\", target_size = (64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78aa5299",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db47cb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = r\"C:\\Users\\ASUS\\Desktop\\coding\\Python\\Deep Learning\\Malaria Cell Detection\\Malarial Cell Image Data\\malarial_cell_image_data\\cell_images\\cell_images\"\n",
    "size = 64\n",
    "dataset = []\n",
    "label = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a1c5592",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 13780/13780 [00:14<00:00, 939.73it/s]\n"
     ]
    }
   ],
   "source": [
    "parasitized_img = os.listdir(image_dir + \"\\\\Parasitized\")\n",
    "\n",
    "for i, img_name in enumerate(tqdm(parasitized_img)):\n",
    "    if(img_name.split('.')[1] == 'png'):\n",
    "        image = cv2.imread(image_dir + \"\\\\Parasitized\\\\\" + img_name)\n",
    "        image = Image.fromarray(image, 'RGB')\n",
    "        image = image.resize((size, size))\n",
    "        \n",
    "        dataset.append(np.array(image))\n",
    "        label.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ac1abb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 13780/13780 [00:13<00:00, 1022.24it/s]\n"
     ]
    }
   ],
   "source": [
    "uninfected_img = os.listdir(image_dir+\"\\\\Uninfected\")\n",
    "\n",
    "for i,img_name in enumerate(tqdm(uninfected_img)):\n",
    "    if(img_name.split('.')[1] == 'png'):\n",
    "        image = cv2.imread(image_dir + \"\\\\Uninfected\\\\\" + img_name)\n",
    "        image = Image.fromarray(image,'RGB')\n",
    "        image = image.resize((size , size))\n",
    "        \n",
    "        dataset.append(np.array(image))\n",
    "        label.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d2ab05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset, to_categorical(np.array(label)), test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a7edad",
   "metadata": {},
   "source": [
    "# CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f916b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_shape = (size,size,3)\n",
    "\n",
    "inp = L.Input(shape = Input_shape)\n",
    "\n",
    "conv1 = L.Conv2D(32,kernel_size = (3,3),activation = \"relu\",padding=\"same\")(inp)\n",
    "pool1 = L.MaxPool2D(pool_size = (2,2))(conv1)\n",
    "norm1 = L.BatchNormalization(axis = -1)(pool1)\n",
    "drop1 = L.Dropout(rate = 0.2)(norm1)\n",
    "\n",
    "conv2 = L.Conv2D(32,kernel_size = (3,3),activation = \"relu\",padding=\"same\")(drop1)\n",
    "pool2 = L.MaxPool2D(pool_size = (2,2))(conv2)\n",
    "norm2 = L.BatchNormalization(axis = -1)(pool2)\n",
    "drop2 = L.Dropout(rate = 0.2)(norm2)\n",
    "\n",
    "conv3 = L.Conv2D(32,kernel_size = (3,3),activation = \"relu\",padding=\"same\")(drop2)\n",
    "pool3 = L.MaxPool2D(pool_size = (2,2))(conv3)\n",
    "norm3 = L.BatchNormalization(axis = -1)(pool3)\n",
    "drop3 = L.Dropout(rate = 0.2)(norm3)\n",
    "\n",
    "flat = L.Flatten()(drop3)\n",
    "\n",
    "hidden1 = L.Dense(512,activation=\"relu\")(flat)\n",
    "norm3   = L.BatchNormalization(axis=-1)(hidden1)\n",
    "drop3   = L.Dropout(rate=0.2)(norm3)\n",
    "\n",
    "hidden2 = L.Dense(256,activation=\"relu\")(drop3)\n",
    "norm4   = L.BatchNormalization(axis=-1)(hidden2)\n",
    "drop4   = L.Dropout(rate=0.2)(norm4)\n",
    "\n",
    "out = L.Dense(2, activation='sigmoid')(drop4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d061b14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 32, 32, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 32, 32, 32)        128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 16, 16, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 16, 16, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 8, 8, 32)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 8, 8, 32)          128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 8, 8, 32)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1049088   \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1203778 (4.59 MB)\n",
      "Trainable params: 1202050 (4.59 MB)\n",
      "Non-trainable params: 1728 (6.75 KB)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = keras.Model(inputs = inp , outputs = out)\n",
    "model.compile(optimizer = 'adam',loss='categorical_crossentropy',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d4e2632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "311/311 [==============================] - 71s 221ms/step - loss: 0.5104 - accuracy: 0.7719 - val_loss: 2.8317 - val_accuracy: 0.6150\n",
      "Epoch 2/10\n",
      "311/311 [==============================] - 64s 207ms/step - loss: 0.2249 - accuracy: 0.9169 - val_loss: 0.3147 - val_accuracy: 0.9116\n",
      "Epoch 3/10\n",
      "311/311 [==============================] - 60s 192ms/step - loss: 0.1787 - accuracy: 0.9379 - val_loss: 0.3286 - val_accuracy: 0.8984\n",
      "Epoch 4/10\n",
      "311/311 [==============================] - 60s 192ms/step - loss: 0.1594 - accuracy: 0.9449 - val_loss: 0.1983 - val_accuracy: 0.9311\n",
      "Epoch 5/10\n",
      "311/311 [==============================] - 66s 211ms/step - loss: 0.1401 - accuracy: 0.9523 - val_loss: 0.2279 - val_accuracy: 0.9215\n",
      "Epoch 6/10\n",
      "311/311 [==============================] - 66s 212ms/step - loss: 0.1297 - accuracy: 0.9539 - val_loss: 0.1677 - val_accuracy: 0.9420\n",
      "Epoch 7/10\n",
      "311/311 [==============================] - 58s 187ms/step - loss: 0.1215 - accuracy: 0.9563 - val_loss: 0.1385 - val_accuracy: 0.9560\n",
      "Epoch 8/10\n",
      "311/311 [==============================] - 65s 208ms/step - loss: 0.1165 - accuracy: 0.9572 - val_loss: 0.1534 - val_accuracy: 0.9537\n",
      "Epoch 9/10\n",
      "311/311 [==============================] - 76s 243ms/step - loss: 0.1092 - accuracy: 0.9626 - val_loss: 0.1494 - val_accuracy: 0.9501\n",
      "Epoch 10/10\n",
      "311/311 [==============================] - 91s 292ms/step - loss: 0.1022 - accuracy: 0.9642 - val_loss: 0.1653 - val_accuracy: 0.9537\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(np.array(X_train),y_train,\n",
    "                   batch_size= 64,verbose=1,epochs = 10,validation_split=0.1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6d367cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173/173 [==============================] - 3s 18ms/step - loss: 0.1733 - accuracy: 0.9512\n",
      "Test accuracy: 95.12%\n"
     ]
    }
   ],
   "source": [
    "print(\"Test accuracy: {:.2f}%\".format(model.evaluate(np.array(X_test),np.array(y_test))[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "290aa398",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(\"malaria_cell_detection_tf213.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
